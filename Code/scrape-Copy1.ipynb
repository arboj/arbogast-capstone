{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ff8fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4d42b",
   "metadata": {},
   "source": [
    "Social Media Data Source Ingesting \n",
    "\tTo pull twitter posts this project used the snscrape python library to pass a query to Twitter's API and execute a search  (Git repository: https://github.com/JustAnotherArchivist/snscrape.) The Twitter API object, returned as a JSON ,includes metadata about the tweet such as date and time of the post, language, how many times the post has been liked, retweeted, or commented on. SNSCRAPE conditions and flattens the JSON as a python readable dictionary. While the API passes a Twitter geo object, a user must manually tag the location or have enabled GPS on the device or browser when posting.. The Twitter API also returns a Twitter geo object, depending on whether or not a user opts into to manually geotag a post, or their settings allow an exact GPS coordinates (https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/geo.)  A few practical problems arise with the use of the geo object from twitter which make the locational information of lesser interest . A user could post about events that occur in a disparate location from where their device is located, rendering the GPS coordinates even if enabled irrelevant. Twitter passes tagged places as a bounding box, which would require identifying the center point of the polygon to convert to a point representation. Previous studies have found user geotagging  rates of 0.85%(https://doi.org/10.5153/sro.3001) to 2.31%(Huang, Binxuan & Carley, Kathleen M. (2019). A Large-Scale Empirical Study of Geotagging Behavior on Twitter. In Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, [pdf]). As such This study will not use the Twitter geo object to determine the relevant location but will leverage a geoparser to identify text based locational information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5680f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Mar  1 10:40:16 2021\n",
    "\n",
    "@author: Arbo\n",
    "\"\"\"\n",
    "\n",
    "def twittsearch(text_query,since_date,until_date,tweetcount):\n",
    "    tweets_list = []\n",
    "\n",
    "    query = '{0} since:{1} until:{2} filter:has_engagement'.format(text_query, since_date, until_date)\n",
    "    print(query)\n",
    "\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "\n",
    "        if i>tweetcount:\n",
    "\n",
    "            break\n",
    "        tweets_list.append([tweet.date, tweet.id, tweet.content, \n",
    "                            tweet.lang,tweet.retweetedTweet,tweet.quotedTweet])\n",
    "\n",
    "    # Creating a dataframe from the tweets list above\n",
    "\n",
    "    tweets_df = pd.DataFrame(tweets_list, \n",
    "                             columns=['Datetime', 'TweetId', 'Text',\n",
    "                                     \"Language\", \"RTFrom\", \"QTFrom\"])\n",
    "    \n",
    "    print(\"found {} tweets ranging from {} to {}\".format(len(tweets_df),\n",
    "                                                            tweets_df.Datetime.min(),tweets_df.Datetime.max()))\n",
    "    \n",
    "    print(\"dropping duplicates\")   \n",
    "    tweets_df = tweets_df.drop_duplicates(subset=['TweetId'])\n",
    "    print(\"total of tweets now: {}\".format(len(tweets_df)))\n",
    "    print(\"english only\")\n",
    "\n",
    "    tweets_df = tweets_df[tweets_df[\"Language\"]=='en']\n",
    "    print(\"total of tweets now: {}\".format(len(tweets_df)))\n",
    "    tweets_df = tweets_df[tweets_df[\"RTFrom\"].isna()]\n",
    "    print(\"total of tweets now: {}\".format(len(tweets_df)))\n",
    "    tweets_df = tweets_df[tweets_df[\"QTFrom\"].isna()]\n",
    "    print(\"total of tweets now: {} ranging from {} to {}\".format(len(tweets_df),\n",
    "                                                                tweets_df.Datetime.min(),tweets_df.Datetime.max()))\n",
    "    \n",
    "    return tweets_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd932a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping commenced at 2021-07-14 23:02:03.098863\n",
      "(\"forest fire\") OR wildfire OR bushfire OR (extreme heat) OR (record heat) OR heatwave OR (\"heat wave\") OR typhoon OR cyclone OR hurricane OR tornado OR (\"storm surge\") OR  blizzard OR snow OR (\"ice storm\") OR sleet OR thunderstorm OR hail OR flood OR flooding OR freeze OR frost OR (extreme cold) OR landslide OR tsunami OR (\"tidal wave\") OR earthquake OR eruption OR volcano OR lava OR lahar OR avalanche OR mudslide OR sinkhole since:2021-07-04 until:2021-07-05 filter:has_engagement\n",
      "found 64326 tweets ranging from 2021-07-04 00:00:00+00:00 to 2021-07-04 23:59:59+00:00\n",
      "dropping duplicates\n",
      "total of tweets now: 64326\n",
      "english only\n",
      "total of tweets now: 34134\n",
      "total of tweets now: 34134\n",
      "total of tweets now: 31630 ranging from 2021-07-04 00:00:00+00:00 to 2021-07-04 23:59:59+00:00\n",
      "Scraping ended at 2021-07-14 23:13:06.883567\n",
      "Scraping time 0:11:03.784704\n"
     ]
    }
   ],
   "source": [
    "scrapestart =  datetime.datetime.now() \n",
    "print(\"Scraping commenced at {}\".format(scrapestart))\n",
    "# =============================================================================\n",
    "text_query = '(\"forest fire\") OR wildfire OR bushfire OR \\\n",
    "(extreme heat) OR (record heat) OR heatwave OR (\"heat wave\") OR typhoon OR cyclone OR hurricane OR \\\n",
    "tornado OR (\"storm surge\") OR  blizzard OR snow OR (\"ice storm\") OR sleet OR thunderstorm OR \\\n",
    "hail OR flood OR flooding OR freeze OR frost OR (extreme cold) OR landslide OR tsunami OR (\"tidal wave\") OR \\\n",
    "earthquake OR eruption OR volcano OR lava OR lahar OR avalanche OR mudslide OR sinkhole'\n",
    "\n",
    "since_date = '2021-06-07'\n",
    "until_date = '2021-06-08'\n",
    "tweetcount = 150000\n",
    "\n",
    "twittsearch(text_query,since_date,until_date,tweetcount).to_csv(os.path.join(tweet_dir,'tweets_df_{0}_{1}.csv'.\n",
    "                              format(since_date.replace('-',''),until_date.replace('-',''))),\n",
    "                 index =False)\n",
    "# =============================================================================\n",
    "scrapend =  datetime.datetime.now()\n",
    "print(\"Scraping ended at {}\".format(scrapend))\n",
    "print(\"Scraping time {}\".format(scrapend-scrapestart))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
